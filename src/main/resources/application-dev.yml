server:
  port: 9001

security:
  jwt:
    token:
      secret-key: power#!api@$
      expire-length: 3600000

spring:
  datasource:
    type: com.alibaba.druid.pool.DruidDataSource
    druid:
      url: jdbc:mysql://111.230.151.93:3306/elqtt?characterEncoding=utf-8
      username: kafka
      password: kafka
      # 配置初始化大小、最小、最大
      initial-size: 5
      min-idle: 5
      max-active: 10
      # 配置从连接池获取连接等待超时的时间
      max-wait: 60000
      # 打开PSCache，并且指定每个连接上PSCache的大小，Oracle等支持游标的数据库，打开此开关，会以数量级提升性能
      pool-prepared-statements: true
      max-pool-prepared-statement-per-connection-size: 20
      # 配置间隔多久启动一次DestroyThread，对连接池内的连接才进行一次检测，单位是毫秒。检测时:
      #   1.如果连接空闲并且超过minIdle以外的连接，如果空闲时间超过minEvictableIdleTimeMillis设置的值则直接物理关闭。
      #   2.在minIdle以内的不处理。
      time-between-eviction-runs-millis: 60000
      # 配置一个连接在池中最大空闲时间，单位是毫秒
      min-evictable-idle-time-millis: 300000
      # 检验连接是否有效的查询语句
      validation-query: SELECT 1
      # 设置从连接池获取连接时是否检查连接有效性
      test-while-idle: true
      # 设置从连接池获取连接时是否检查连接有效性
      test-on-borrow: false
      # 设置往连接池归还连接时是否检查连接有效性
      test-on-return: false
      # 打开后，增强timeBetweenEvictionRunsMillis的周期性连接检查，minIdle内的空闲连接，每次检查强制验证连接有效性
      keep-alive: true
      # 连接泄露检查，打开removeAbandoned功能 , 连接从连接池借出后，长时间不归还，将触发强制回连接。
      # 回收周期随timeBetweenEvictionRunsMillis进行，如果连接为从连接池借出状态，并且未执行任何sql，并且从借出时间起已超过removeAbandonedTimeout时间，则强制归还连接到连接池中。
      removeAbandoned: true
      removeAbandonedTimeout: 150 #秒
      # 关闭abanded连接时输出错误日志，这样出现连接泄露时可以通过错误日志定位忘记关闭连接的位置
      logAbandoned: true
      filter:
        slf4j:
          enabled: true
          statement-log-enabled: false
          statement-executable-sql-log-enable: true
          statement-log-error-enabled: true
          statement-sql-format-option:
            parameterized: false
            prettyFormat: false
            uppCase: false
  kafka:
    # 指定kafka 代理地址，可以多个
    bootstrap-servers: 111.230.151.93:9092
    producer:
      type: async
      request:
        required:
          acks: 1
      queue:
        buffering:
          max:
            ms: 5000
            messages: 10000
        enqueue:
          timeout:
            ms: -1
      batch:
        num:
          messages: 200
      retries: 0
      # 每次批量发送消息的数量
      batch-size: 16384
      # 缓存容量
      buffer-memory: 33554432
      # 指定消息key和消息体的编解码方式
      key-serializer: org.apache.kafka.common.serialization.StringSerializer
      value-serializer: org.apache.kafka.common.serialization.StringSerializer
    consumer:
      # 指定默认消费者group id
      group-id: power
      auto-commit-interval: 100
      auto-offset-reset: earliest
      enable-auto-commit: true
      # 指定消息key和消息体的编解码方式
      key-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      value-deserializer: org.apache.kafka.common.serialization.StringDeserializer
    # 指定listener 容器中的线程数，用于提高并发量
    listener:
      concurrency: 3
# emq连接配置
mqtt:
  url: tcp://111.230.151.93:1883
  clean-start: true
  client-id: receiver
  reconnection-delay: 2000
  reconnection-attempt_max: 6
  keep-alive: 30

# 环境部署
# 在jmeter/bin 文件夹下面，启动jmeter并且设置jvm内存命令：JVM_ARGS="-Xms1024m -Xmx2048m -XX:NewSize=512m -XX:MaxNewSize=1024m" && export JVM_ARGS &&./jmeter.sh
# 在docker文件夹下面运行：docker-composes up -d 启动zookeeper 和 kafka
# 打开集群：启动2个 kafka docker-compose scale kafka=2
# emq环境：https://juejin.im/post/5ba0c5155188255c9b13ab45
# docker run --name emq -p 18083:18083 -p 1883:1883 -p 8084:8084 -p 8883:8883 -p 8083:8083 -d registry.cn-hangzhou.aliyuncs.com/synbop/emqttd:2.3.6
# docker run --rm -ti --name emq -e "EMQ_TCP_PORT=1883" -p 18083:18083 -p 1883:1883 sneck/emqttd:latest